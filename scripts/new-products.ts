#!/usr/bin/env tsx

/**
 * New Products Script
 * 
 * This script processes products from a shop and creates records in the Supabase products table.
 * Follows the instructions from agents/new-products.md
 * 
 * Usage: 
 *   tsx scripts/new-products.ts <shop-identifier> [product-url-1] [product-url-2] ...
 *   tsx scripts/new-products.ts <shop-identifier> --limit 2
 * 
 * Examples:
 *   tsx scripts/new-products.ts yoursurprise.com https://www.yoursurprise.com/product1 https://www.yoursurprise.com/product2
 *   tsx scripts/new-products.ts yoursurprise.com --limit 2
 *   npm run new-products yoursurprise.com
 */

// Load environment variables
import { config } from 'dotenv'
import { resolve } from 'path'

// Try to load .env.local first, then .env
config({ path: resolve(process.cwd(), '.env.local') })
config({ path: resolve(process.cwd(), '.env') })

import { createAdminClient } from '../src/lib/supabase/admin'
import { readFileSync, writeFileSync, existsSync, mkdirSync } from 'fs'
import { join } from 'path'
import { spawn } from 'child_process'

interface ProductData {
  shop_id: string
  title: string
  slug: string
  url: string
  price: number | null
  price_discount: number | null
  description: string
  specifications: object
  images: string[]
  filters: object
  categories: string[] // Category slugs or titles to match
  thread_text?: string // Optional: Thread text generated by AI assistant
  thread_keywords?: string // Optional: Thread keywords generated by AI assistant
}

interface ExtractedProductInfo {
  title?: string
  url: string
  price?: number | null
  price_discount?: number | null
  images?: string[]
  specifications?: object
  textContent?: string
  categories?: string[]
}

/**
 * Add product to Amazon bestsellers checklist
 */
function addToChecklist(productUrl: string, productTitle: string, productId: string, ageFilters: string[], category: string): void {
  const checklistPath = join(process.cwd(), 'agents/data/amazon-bestsellers-checklist.md')
  
  // Only add if URL is from Amazon
  if (!productUrl.includes('amazon.com') && !productUrl.includes('amzn.to')) {
    return
  }
  
  // Read existing content
  let content = ''
  if (existsSync(checklistPath)) {
    content = readFileSync(checklistPath, 'utf-8')
  } else {
    content = `# Amazon Bestsellers Checklist

This file tracks all products that have been successfully added to the database from Amazon bestseller searches. When searching for new bestseller products, check this list first to avoid processing the same products again.

Each line contains a single Amazon product URL (affiliate link if available, or direct Amazon URL).

## Products Added

`
  }
  
  // Extract base URL (remove query parameters for consistency)
  const baseUrl = productUrl.split('?')[0].trim()
  
  // Extract ASIN from URL to also add /dp/ASIN format
  let asin: string | null = null
  const asinMatch = productUrl.match(/\/(?:dp|gp\/product)\/([A-Z0-9]{10})(?:[/?]|$)/)
  if (asinMatch) {
    asin = asinMatch[1]
  }
  
  // Check if URL already exists in checklist (check both affiliate link and /dp/ASIN format)
  const existingUrls = content.match(/^https?:\/\/[^\s]+$/gm) || []
  const normalizedExistingUrls = existingUrls.map(url => url.split('?')[0].trim())
  
  // Check if base URL exists
  if (normalizedExistingUrls.includes(baseUrl)) {
    // URL already exists, skip
    return
  }
  
  // Also check if /dp/ASIN format exists (if we have ASIN)
  if (asin) {
    const dpUrl = `https://www.amazon.com/dp/${asin}`
    if (normalizedExistingUrls.includes(dpUrl)) {
      // /dp/ASIN format already exists, skip
      return
    }
  }
  
  // Find the "## Products Added" section and add URL after it
  // Prefer affiliate link (amzn.to) if available, otherwise use product URL
  const urlToAdd = baseUrl // Use the provided URL (should be affiliate link if available)
  
  const productsSectionIndex = content.indexOf('## Products Added')
  if (productsSectionIndex === -1) {
    // Section not found, append to end
    content += `\n${urlToAdd}\n`
  } else {
    // Find the end of the header line
    const afterHeaderIndex = content.indexOf('\n', productsSectionIndex) + 1
    // Insert URL after the header
    content = content.slice(0, afterHeaderIndex) + `${urlToAdd}\n` + content.slice(afterHeaderIndex)
  }
  
  // Write back to file
  writeFileSync(checklistPath, content, 'utf-8')
  console.log(`   üìù Added to checklist: ${productTitle.substring(0, 50)}...`)
}

/**
 * Validate product images
 * Checks if images are valid and match the product URL
 */
function validateProductImages(images: string[], productUrl: string, productTitle: string): { valid: boolean; warnings: string[] } {
  const warnings: string[] = []
  
  // Check if images array is empty
  if (!images || images.length === 0) {
    warnings.push('‚ö†Ô∏è  No images found for product')
    return { valid: false, warnings }
  }
  
  // Extract ASIN from product URL for Amazon products
  let productAsin: string | null = null
  if (productUrl.includes('amazon.com') || productUrl.includes('amzn.to')) {
    const asinMatch = productUrl.match(/\/([A-Z0-9]{10})(?:[/?]|$)/)
    if (asinMatch) {
      productAsin = asinMatch[1]
    }
  }
  
  // Check each image
  const invalidImages: string[] = []
  const validImages: string[] = []
  
  for (let i = 0; i < images.length; i++) {
    const imageUrl = images[i]
    
    // Check if image URL is valid
    if (!imageUrl || typeof imageUrl !== 'string' || imageUrl.trim().length === 0) {
      invalidImages.push(`Image ${i + 1}: Empty or invalid URL`)
      continue
    }
    
    // Check if image URL is a valid HTTP/HTTPS URL
    if (!imageUrl.match(/^https?:\/\//i)) {
      invalidImages.push(`Image ${i + 1}: Invalid URL format (${imageUrl.substring(0, 50)}...)`)
      continue
    }
    
    // For Amazon products, check if image URL contains the product ASIN
    if (productAsin && imageUrl.includes('amazon.com')) {
      // Extract ASIN from image URL (Amazon image URLs sometimes contain ASIN in the path)
      const imageAsinMatch = imageUrl.match(/\/I\/([A-Z0-9]{10})/i)
      if (imageAsinMatch) {
        const imageAsin = imageAsinMatch[1]
        // Note: Amazon image ASINs don't always match product ASINs, so we'll just check if it's a valid Amazon image URL
      }
      
      // Check if image URL looks like a valid Amazon image URL
      if (!imageUrl.match(/\/images\/I\/[A-Z0-9]+/i)) {
        warnings.push(`Image ${i + 1}: Amazon image URL format may be incorrect (${imageUrl.substring(0, 50)}...)`)
      }
    }
    
    validImages.push(imageUrl)
  }
  
  // Report invalid images
  if (invalidImages.length > 0) {
    warnings.push(`‚ö†Ô∏è  Found ${invalidImages.length} invalid image(s):`)
    invalidImages.forEach(warning => warnings.push(`   ${warning}`))
  }
  
  // Check if we have at least one valid image
  if (validImages.length === 0) {
    warnings.push('‚ùå No valid images found for product')
    return { valid: false, warnings }
  }
  
  // Check if we have too few images (warning, not error)
  if (validImages.length < 3) {
    warnings.push(`‚ÑπÔ∏è  Only ${validImages.length} image(s) found - consider adding more images for better product presentation`)
  }
  
  // Check for duplicate images
  const uniqueImages = [...new Set(validImages)]
  if (uniqueImages.length !== validImages.length) {
    warnings.push(`‚ö†Ô∏è  Found ${validImages.length - uniqueImages.length} duplicate image(s)`)
  }
  
  return { valid: validImages.length > 0, warnings }
}

/**
 * Generate slug from title
 */
function generateSlug(title: string): string {
  return title
    .toLowerCase()
    .trim()
    .replace(/[^\w\s-]/g, '')
    .replace(/\s+/g, '-')
    .replace(/-+/g, '-')
    .replace(/^-|-$/g, '')
}

/**
 * Extract domain from URL
 */
function extractDomain(url: string): string {
  try {
    const urlObj = new URL(url.startsWith('http') ? url : `https://${url}`)
    return urlObj.hostname.replace(/^www\./, '')
  } catch {
    return url.replace(/^https?:\/\//, '').replace(/^www\./, '').split('/')[0]
  }
}

/**
 * Fetch and parse HTML from URL
 * Handles Amazon affiliate links (amzn.to) by following redirects
 */
async function fetchWebsite(url: string): Promise<string> {
  const fullUrl = url.startsWith('http') ? url : `https://${url}`
  console.log(`Fetching: ${fullUrl}`)
  
  try {
    // For Amazon affiliate links, we need to follow redirects
    const response = await fetch(fullUrl, {
      headers: {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Cache-Control': 'max-age=0',
      },
      redirect: 'follow', // Explicitly follow redirects
    })
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`)
    }
    
    const html = await response.text()
    
    // For Amazon affiliate links, check if we got redirected to the actual product page
    // If the HTML doesn't contain product page elements, it might be a redirect page
    if (url.includes('amzn.to') || url.includes('amazon.com')) {
      // Check if we have product page content
      const hasProductContent = html.includes('productTitle') || 
                                html.includes('landingImage') || 
                                html.includes('id="title"') ||
                                html.includes('data-asin')
      
      if (!hasProductContent && response.url && response.url !== fullUrl) {
        // We were redirected, but the HTML might not be fully loaded
        // Try fetching the final URL directly
        console.log(`   ‚ÑπÔ∏è  Followed redirect to: ${response.url}`)
        const finalResponse = await fetch(response.url, {
          headers: {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'max-age=0',
          },
          redirect: 'follow',
        })
        
        if (finalResponse.ok) {
          return await finalResponse.text()
        }
      }
    }
    
    return html
  } catch (error) {
    console.error(`Error fetching website: ${error}`)
    throw error
  }
}

/**
 * Extract product information from HTML
 */
function extractProductInfo(html: string, url: string): ExtractedProductInfo {
  const info: ExtractedProductInfo = { url }
  const isAmazon = url.includes('amazon.') || url.includes('amzn.to');

  // Amazon Specific Logic
  if (isAmazon) {
    // Title extraction - try multiple methods
    // Method 1: id="productTitle" (most reliable for Amazon)
    let titleMatch = html.match(/id="productTitle"[^>]*>[\s\S]*?<span[^>]*id="productTitle"[^>]*>([\s\S]*?)<\/span>/i)
    if (titleMatch && titleMatch[1]) {
      info.title = titleMatch[1].trim()
    }
    
    // Method 2: id="title" with span inside
    if (!info.title) {
      titleMatch = html.match(/id="title"[^>]*>[\s\S]*?<span[^>]*id="productTitle"[^>]*>([\s\S]*?)<\/span>/i)
      if (titleMatch && titleMatch[1]) {
        info.title = titleMatch[1].trim()
      }
    }
    
    // Method 3: id="title" with h1 or span
    if (!info.title) {
      titleMatch = html.match(/id="title"[^>]*>[\s\S]*?<(?:h1|span)[^>]*>([\s\S]*?)<\/(?:h1|span)>/i)
      if (titleMatch && titleMatch[1]) {
        info.title = titleMatch[1].trim()
      }
    }
    
    // Method 4: Simple id="title" or id="productTitle"
    if (!info.title) {
      titleMatch = html.match(/id="(?:product)?title"[^>]*>([\s\S]*?)<\//i)
      if (titleMatch && titleMatch[1]) {
        // Clean up - remove HTML tags and style tags
        let title = titleMatch[1].trim()
        // Remove style tags
        title = title.replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
        // Remove script tags
        title = title.replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
        // Remove all HTML tags
        title = title.replace(/<[^>]+>/g, ' ')
        // Clean up whitespace
        title = title.replace(/\s+/g, ' ').trim()
        if (title.length > 10) {
          info.title = title
        }
      }
    }
    
    // Method 5: og:title meta tag
    if (!info.title) {
      titleMatch = html.match(/<meta[^>]*property=["']og:title["'][^>]*content=["']([^"']+)["']/i)
      if (titleMatch && titleMatch[1]) {
        let title = titleMatch[1].trim()
        // Remove Amazon branding
        title = title.replace(/\s*[|\-‚Äì‚Äî]\s*Amazon[^|]*$/i, '').trim()
        if (title.length > 10) {
          info.title = title
        }
      }
    }

    // Images from Amazon - Extract full-size images
    const extractedImages: string[] = []
    
    // Extract ASIN from product URL to verify images belong to this product
    const productAsinMatch = url.match(/\/([A-Z0-9]{10})(?:[/?]|$)/)
    const productAsin = productAsinMatch ? productAsinMatch[1] : null

    /**
     * Clean Amazon image URL to get full-size version
     * Removes size parameters like ._SX38_SY50_, ._AC_US40_, etc.
     * For full-size images, we want to use ._AC_SL1500_ or larger, or remove size params entirely
     */
    function cleanAmazonImageUrl(url: string): string {
      if (!url || (!url.includes('amazon.com') && !url.includes('amzn.to'))) {
        return url
      }
      
      // If URL already has a large size indicator (SL1500, SL2000, etc.), keep it but clean other params
      const hasLargeSize = url.match(/\._AC_SL[1-9]\d{3,}_/) // SL1500, SL2000, etc.
      
      if (hasLargeSize) {
        // Keep the large size indicator, but remove other unnecessary params
        let cleanUrl = url
          .replace(/\._SX\d+_SY\d+_/g, '') // Remove ._SX38_SY50_ type params
          .replace(/\._AC_US\d+_/g, '') // Remove small size ._AC_US40_ type params
          .replace(/\._AC_SR\d+,\d+_/g, '') // Remove ._AC_SR38,50_ type params
          .replace(/\._CR,\d+,\d+,\d+,\d+_/g, '') // Remove crop params like ._CR,0,0,38,50_
          .replace(/\.CR,\d+,\d+,\d+,\d+_/g, '') // Remove crop params without leading dot
          .replace(/\._BG\d+,\d+,\d+_/g, '') // Remove background params
          .replace(/\._PKdp[^_]*_/g, '') // Remove overlay params
          .replace(/\?[^"]*$/, '') // Remove query params
          .replace(/\.\.+/g, '.') // Fix double dots
        return cleanUrl
      }
      
      // For URLs without large size indicators, try to convert to a large size format
      // Amazon full-size images typically use ._AC_SL1500_ or similar
      let cleanUrl = url
        // First, try to replace small size indicators with large ones
        .replace(/\._SX\d+_SY\d+_/, '._AC_SL1500_.')
        .replace(/\._AC_US\d+_/, '._AC_SL1500_.')
        .replace(/\._AC_SR\d+,\d+_/, '._AC_SL1500_.')
        .replace(/\._SX\d+_/, '._AC_SL1500_.')
        .replace(/\._SY\d+_/, '._AC_SL1500_.')
        // Remove other unnecessary params
        .replace(/\._CR,\d+,\d+,\d+,\d+_/g, '')
        .replace(/\.CR,\d+,\d+,\d+,\d+_/g, '') // Remove crop params without leading dot
        .replace(/\._BG\d+,\d+,\d+_/g, '')
        .replace(/\._PKdp[^_]*_/g, '')
        .replace(/\?[^"]*$/, '')
        .replace(/\.\.+/g, '.') // Fix double dots
      
      // If we still don't have a size indicator and it's an Amazon image, add one
      if (cleanUrl.includes('amazon.com') && !cleanUrl.match(/\._AC_SL\d+_/)) {
        // Insert ._AC_SL1500_ before the file extension
        cleanUrl = cleanUrl.replace(/(\.(jpg|jpeg|png|webp|gif))(\?|$)/i, '._AC_SL1500_$1$3')
      }
      
      // Ensure we have a proper image extension
      if (!cleanUrl.match(/\.(jpg|jpeg|png|webp|gif)(\?|$)/i)) {
        // If no extension, try to add .jpg (Amazon default)
        if (cleanUrl.includes('amazon.com')) {
          cleanUrl = cleanUrl.replace(/[._]+$/, '') + '.jpg'
        }
      }
      
      return cleanUrl
    }

    // 1. #landingImage - Main Product Image (full size)
    // CRITICAL: Only extract images from the landingImage element which is specific to this product page
    const landingImageContainer = html.match(/id="landingImage"[^>]*>([\s\S]*?)<\/div>/i)
    if (landingImageContainer) {
      const landingImageContent = landingImageContainer[1]
      
      // First try: data-a-dynamic-image attribute (most reliable)
      const landingImageMatch = landingImageContent.match(/data-a-dynamic-image="([^"]+)"/i)
      if (landingImageMatch) {
        try {
          // data-a-dynamic-image contains JSON with different image sizes
          const dynamicImageJson = landingImageMatch[1].replace(/&quot;/g, '"').replace(/&amp;/g, '&')
          const dynamicImages = JSON.parse(dynamicImageJson)
          // Get ALL images from dynamic data, not just the largest
          const imageUrls = Object.keys(dynamicImages)
          if (imageUrls.length > 0) {
            // Sort by potential size (URLs with larger numbers usually mean larger images)
            const sortedUrls = imageUrls.sort((a, b) => {
              const aSize = a.match(/_SX(\d+)_|_AC_SL(\d+)_/) || [0, '0']
              const bSize = b.match(/_SX(\d+)_|_AC_SL(\d+)_/) || [0, '0']
              const aSizeNum = parseInt(String(aSize[1] || aSize[2] || '0'))
              const bSizeNum = parseInt(String(bSize[1] || bSize[2] || '0'))
              return bSizeNum - aSizeNum
            })
            // Add the largest image (first in sorted list)
            const largestUrl = cleanAmazonImageUrl(sortedUrls[0])
            if (largestUrl && !extractedImages.includes(largestUrl)) {
              extractedImages.push(largestUrl)
            }
          }
        } catch (e) {
          // Fallback: try to extract src directly from landingImage
          const landingSrcMatch = landingImageContent.match(/src="([^"]+)"/i)
          if (landingSrcMatch) {
            const cleanedUrl = cleanAmazonImageUrl(landingSrcMatch[1])
            if (cleanedUrl && !extractedImages.includes(cleanedUrl)) {
              extractedImages.push(cleanedUrl)
            }
          }
        }
      } else {
        // Fallback: try to extract src directly from landingImage
        const landingSrcMatch = landingImageContent.match(/src="([^"]+)"/i)
        if (landingSrcMatch) {
          const cleanedUrl = cleanAmazonImageUrl(landingSrcMatch[1])
          if (cleanedUrl && !extractedImages.includes(cleanedUrl)) {
            extractedImages.push(cleanedUrl)
          }
        }
      }
    }

    // 2. #altImages - Gallery Images (extract hi-res versions)
    // CRITICAL: Only extract from altImages container which is specific to this product
    const altImagesContainer = html.match(/id="altImages"[^>]*>([\s\S]*?)<\/ul>/i) || html.match(/id="altImages"[^>]*>([\s\S]*?)<\/div>/i)
    if (altImagesContainer) {
      const altContent = altImagesContainer[1]
      
      // Extract hi-res images from input elements (these are usually full-size)
      // These are specifically within the altImages container for this product
      const inputMatches = altContent.matchAll(/<input[^>]*class="[^"]*hi-res[^"]*"[^>]*value="([^"]+)"/gi)
      for (const match of inputMatches) {
        const cleanedUrl = cleanAmazonImageUrl(match[1])
        if (cleanedUrl && !extractedImages.includes(cleanedUrl)) {
          extractedImages.push(cleanedUrl)
        }
      }
      
      // Also check data-a-dynamic-image in altImages (get all images, not just one)
      // CRITICAL: Only from within altImages container
      const altDynamicMatches = altContent.matchAll(/data-a-dynamic-image="([^"]+)"/gi)
      for (const match of altDynamicMatches) {
        try {
          const dynamicImageJson = match[1].replace(/&quot;/g, '"').replace(/&amp;/g, '&')
          const dynamicImages = JSON.parse(dynamicImageJson)
          const imageUrls = Object.keys(dynamicImages)
          if (imageUrls.length > 0) {
            const sortedUrls = imageUrls.sort((a, b) => {
              const aSize = a.match(/_SX(\d+)_|_AC_SL(\d+)_/) || [0, '0']
              const bSize = b.match(/_SX(\d+)_|_AC_SL(\d+)_/) || [0, '0']
              const aSizeNum = parseInt(String(aSize[1] || aSize[2] || '0'))
              const bSizeNum = parseInt(String(bSize[1] || bSize[2] || '0'))
              return bSizeNum - aSizeNum
            })
            // Add the largest image from each dynamic image set
            const cleanedUrl = cleanAmazonImageUrl(sortedUrls[0])
            if (cleanedUrl && !extractedImages.includes(cleanedUrl)) {
              extractedImages.push(cleanedUrl)
            }
          }
        } catch (e) {
          // Skip if JSON parsing fails
        }
      }
      
      // Also extract from img tags in altImages (as fallback)
      // CRITICAL: Only from within altImages container
      const altImgMatches = altContent.matchAll(/<img[^>]*src="([^"]+)"[^>]*>/gi)
      for (const match of altImgMatches) {
        const url = match[1]
        if (url && (url.includes('amazon.com') || url.includes('media-amazon.com'))) {
          const cleanedUrl = cleanAmazonImageUrl(url)
          if (cleanedUrl && !extractedImages.includes(cleanedUrl)) {
            extractedImages.push(cleanedUrl)
          }
        }
      }
    }

    // 3. Try to extract from JSON-LD structured data (often has full-size images)
    // CRITICAL: Only use JSON-LD if it contains product-specific data (check for @type: "Product")
    const jsonLdMatches = html.matchAll(/<script[^>]*type=["']application\/ld\+json["'][^>]*>([\s\S]*?)<\/script>/gi)
    for (const match of jsonLdMatches) {
      try {
        const jsonLd = JSON.parse(match[1])
        // Only extract images from Product schema, not from other schemas
        if (jsonLd['@type'] === 'Product' || (Array.isArray(jsonLd['@type']) && jsonLd['@type'].includes('Product'))) {
          if (jsonLd.image) {
            const images = Array.isArray(jsonLd.image) ? jsonLd.image : [jsonLd.image]
            for (const img of images) {
              const imgUrl = typeof img === 'string' ? img : (img.url || img)
              if (imgUrl && imgUrl.includes('amazon.com')) {
                const cleanedUrl = cleanAmazonImageUrl(imgUrl)
                if (cleanedUrl && !extractedImages.includes(cleanedUrl)) {
                  extractedImages.push(cleanedUrl)
                }
              }
            }
          }
        }
      } catch (e) {
        // Skip if JSON parsing fails
      }
    }
    
    if (extractedImages.length > 0) {
      // Filter out low res, sprites, and ensure we have valid image URLs
      // CRITICAL: Also verify images are from Amazon media domain (not generic placeholders)
      const filteredImages = extractedImages
        .filter(img => {
          if (!img || img.length < 10) return false
          if (img.includes('sprite')) return false
          if (img.includes('transparent')) return false
          if (img.includes('pixel')) return false
          // CRITICAL: Must be from Amazon media domain
          if (!img.includes('media-amazon.com') && !img.includes('images-na.ssl-images-amazon.com')) return false
          // Filter out very small thumbnails (check for small size indicators)
          if (img.match(/\._AC_US[1-9]\d_/) || img.match(/\._AC_US\d[1-9]_/)) return false // US40, US50, etc. are thumbnails
          if (img.match(/\._SX[1-9]\d_SY[1-9]\d_/) || img.match(/\._SX\d[1-9]_SY\d[1-9]_/)) return false // Small sizes like 38x50
          // CRITICAL: Verify image URL contains valid Amazon image identifier (I/ followed by alphanumeric)
          if (!img.match(/\/I\/[A-Z0-9]+/i)) return false
          return true
        })
        .map(img => cleanAmazonImageUrl(img)) // Clean all URLs one more time
      
      // Remove duplicates and ensure we have unique images
      info.images = [...new Set(filteredImages)]
      
      // CRITICAL: Log warning if no images found after filtering
      if (info.images.length === 0 && extractedImages.length > 0) {
        console.warn(`‚ö†Ô∏è  All ${extractedImages.length} extracted images were filtered out. This may indicate a problem with image extraction.`)
      }
      
      // CRITICAL: Log extracted images for debugging
      if (info.images.length > 0) {
        console.log(`   üì∏ Extracted ${info.images.length} image(s) from product page`)
        console.log(`   üì∏ First image: ${info.images[0].substring(0, 80)}...`)
      }
    } else {
      console.warn(`‚ö†Ô∏è  No images extracted from product page. This may indicate a problem with the page structure.`)
    }

    // Description from id="feature-bullets"
    const featureBulletsMatch = html.match(/id="feature-bullets"[^>]*>([\s\S]*?)<\/div>/i)
    if (featureBulletsMatch) {
      const bulletsContent = featureBulletsMatch[1]
      const bullets: string[] = []
      const liMatches = bulletsContent.matchAll(/<li[^>]*>[\s\S]*?<span[^>]*>([\s\S]*?)<\/span>[\s\S]*?<\/li>/gi)
      for (const match of liMatches) {
        bullets.push(match[1].replace(/<[^>]+>/g, '').trim())
      }
      if (bullets.length > 0) {
        info.textContent = bullets.join('\n') // Store as textContent for now, or we could set description directly
      }
    }

    // Specifications from id="productDetails_expanderTables_depthLeftSections"
    const specsMatch = html.match(/id="productDetails_expanderTables_depthLeftSections"[^>]*>([\s\S]*?)<\/div>/i)
    if (specsMatch) {
      const specsContent = specsMatch[1]
      const specs: Record<string, string> = {}
      const rows = specsContent.matchAll(/<tr[^>]*>([\s\S]*?)<\/tr>/gi)
      for (const row of rows) {
        const th = row[1].match(/<th[^>]*>([\s\S]*?)<\/th>/i)
        const td = row[1].match(/<td[^>]*>([\s\S]*?)<\/td>/i)
        if (th && td) {
          const key = th[1].replace(/<[^>]+>/g, '').trim()
          const value = td[1].replace(/<[^>]+>/g, '').trim()
          if (key && value) {
            specs[key] = value
          }
        }
      }
      info.specifications = specs
    }

    // Price from id="lowestPriceDevices_feature_div" (or generic fallbacks)
    // Note: this div might contain multiple prices or complex structures.
    const priceDivMatch = html.match(/id="lowestPriceDevices_feature_div"[^>]*>([\s\S]*?)<\/div>/i)
    if (priceDivMatch) {
      const priceText = priceDivMatch[1].replace(/<[^>]+>/g, ' ').trim()
      // Try to find price numbers
      const prices = priceText.match(/[\d.,]+/g)
      if (prices && prices.length > 0) {
        // This is a naive extraction from that specific div
        // A better approach for Amazon is looking for specific price classes within that div
        // But let's see if generic price extraction works better if this fails
      }
    }
  }
  
  // General Title Extraction (fallback)
  if (!info.title) {
    const titleMatch = html.match(/<title[^>]*>([^<]+)<\/title>/i) ||
                       html.match(/<h1[^>]*>([^<]+)<\/h1>/i) ||
                       html.match(/<meta[^>]*property="og:title"[^>]*content="([^"]+)"/i)
    if (titleMatch) {
      let title = titleMatch[1].trim()
      title = title.replace(/\s*[|\-‚Äì‚Äî]\s*[^|]+$/, '').trim()
      title = title.replace(/\s*-\s*(YourSurprise|Shop|Store|Gifts?)$/i, '').trim()
      info.title = title
    }
  }
  
  // General Price Extraction (supporting discount)
  // Logic: try to find "current" price and "original" price
  
  let currentPrice: number | null = null
  let originalPrice: number | null = null
  
  // 1. Try to find two prices together (common in "Was: $X Now: $Y" patterns)
  // This is hard to regex generically, so we'll look for known patterns
  
  // Check for "list price" or "original price" (strikethrough often)
  const listPricePatterns = [
    /List Price:?\s*<[^>]*>[\s\S]*?([\d.,]+)/i,
    /class="[^"]*strike[^"]*"[^>]*>[\s\S]*?([\d.,]+)/i,
    /class="[^"]*old-price[^"]*"[^>]*>[\s\S]*?([\d.,]+)/i,
    /data-price-type="oldPrice"[^>]*value="([\d.]+)"/i
  ]
  
  for (const pattern of listPricePatterns) {
    const match = html.match(pattern)
    if (match) {
      const p = parseFloat(match[1].replace(/,/g, '.')) // naive replace, assuming dot decimal or comma decimal
      if (!isNaN(p)) {
        originalPrice = p
        break
      }
    }
  }
  
  // 2. Extract standard price (usually current price)
  const pricePatterns = [
    /<meta[^>]*property=["']og:price:amount["'][^>]*content=["']([^"']+)["']/i,
    /<meta[^>]*property=["']product:price:amount["'][^>]*content=["']([^"']+)["']/i,
    /"price":\s*["']?([0-9]+\.?[0-9]*)["']?/i,
    /<[^>]*class=["'][^"']*price[^"']*["'][^>]*>[\s\S]*?([0-9]+[.,][0-9]{2})/i,
    /(?:‚Ç¨|EUR|USD|\$)\s*([0-9]+[.,][0-9]{2})/i,
    /data-price=["']([0-9]+\.?[0-9]*)["']/i,
  ]
  
  for (const pattern of pricePatterns) {
    const match = html.match(pattern)
    if (match) {
      const priceStr = match[1].replace(',', '.').trim()
      const price = parseFloat(priceStr)
      if (!isNaN(price) && price > 0) {
        currentPrice = price
        break
      }
    }
  }
  
  // Amazon specific price fallbacks if generic failed
  if (isAmazon && !currentPrice) {
    // Try .a-price .a-offscreen
    const amazonPrice = html.match(/class="a-price-whole"[^>]*>([\d.,]+)/i)
    if (amazonPrice) {
      currentPrice = parseFloat(amazonPrice[1].replace(/,/g, ''))
      // Check for cents
      const cents = html.match(/class="a-price-fraction"[^>]*>([\d]+)/i)
      if (cents) {
        currentPrice += parseFloat(cents[1]) / 100
      }
    }
  }
  
  // Set prices based on logic:
  // If we have both, and original > current, then:
  // price = originalPrice
  // price_discount = currentPrice
  // (As per user instruction: "Jaunai cenai datubƒÅzes tabulƒÅ lauks 'price_discount'" -> New price is price_discount)
  
  if (originalPrice && currentPrice && originalPrice > currentPrice) {
    info.price = originalPrice
    info.price_discount = currentPrice
  } else {
    // Only one price found, or current >= original (no discount)
    info.price = currentPrice || originalPrice
    info.price_discount = null
  }
  
  // Image extraction (General fallback if not Amazon or if Amazon failed)
  if ((!info.images || info.images.length === 0)) {
    const images: string[] = []
    const baseUrlObj = new URL(url.startsWith('http') ? url : `https://${url}`)
    
    // ... (Existing image extraction logic)
    const imagePatterns = [
      /<img[^>]*src=["']([^"']+)["'][^>]*>/gi,
      /<img[^>]*data-src=["']([^"']+)["'][^>]*>/gi,
      /<img[^>]*data-lazy-src=["']([^"']+)["'][^>]*>/gi,
      /<img[^>]*data-original=["']([^"']+)["'][^>]*>/gi,
      /<img[^>]*srcset=["']([^"']+)["'][^>]*>/gi,
      /style=["'][^"']*background-image:\s*url\(["']?([^"')]+)["']?\)/gi,
      /<meta[^>]*property=["']og:image["'][^>]*content=["']([^"']+)["']/gi,
      /"image":\s*["']([^"']+)["']/gi,
      /"images":\s*\[([^\]]+)\]/gi,
      /<div[^>]*class="[^"]*gallery[^"]*"[^>]*>[\s\S]*?<img[^>]*src=["']([^"']+)["']/gi,
    ]
    
    // Extract from all patterns
    for (const pattern of imagePatterns) {
      const matches = html.matchAll(pattern)
      for (const match of matches) {
        let imgUrl = match[1] || match[0]
        if (imgUrl.includes(',')) {
          const urls = imgUrl.split(',').map(u => u.trim().split(/\s+/)[0])
          for (const u of urls) processImageUrl(u, images, baseUrlObj)
        } else {
          processImageUrl(imgUrl, images, baseUrlObj)
        }
      }
    }
    
    const uniqueImages = [...new Set(images)]
    const fullSizeImages = uniqueImages.filter(url => {
      if (/_thumb/i.test(url) || /width=(58|100|150|200)/i.test(url)) return false
      if (/play-thumb|play-button|video.*thumb/i.test(url)) return false
      return true
    })
    
    info.images = fullSizeImages.length > 0 ? fullSizeImages.slice(0, 20) : uniqueImages.slice(0, 20)
  }
  
  // Text content extraction (if not extracted by Amazon logic)
  if (!info.textContent) {
    const bodyMatch = html.match(/<body[^>]*>([\s\S]*?)<\/body>/i)
    if (bodyMatch) {
      info.textContent = bodyMatch[1]
        .replace(/<script[^>]*>[\s\S]*?<\/script>/gi, '')
        .replace(/<style[^>]*>[\s\S]*?<\/style>/gi, '')
        .replace(/<[^>]+>/g, ' ')
        .replace(/\s+/g, ' ')
        .trim()
        .substring(0, 10000)
    }
  }
  
  return info
}

function processImageUrl(imgUrl: string, imagesArray: string[], baseUrl: URL) {
  if (!imgUrl) return
  
  imgUrl = imgUrl.trim()
    .replace(/&amp;/g, '&')
    .replace(/&lt;/g, '<')
    .replace(/&gt;/g, '>')
  
  const skipPatterns = [
    /logo/i, /icon/i, /avatar/i, /profile/i, /banner/i, /header/i, /footer/i,
    /social/i, /favicon/i, /\.svg/i, /flag/i, /country/i, /payment/i, /badge/i, /button/i,
  ]
  
  if (skipPatterns.some(p => p.test(imgUrl))) return
  
  let fullUrl = imgUrl
  if (imgUrl.startsWith('http')) fullUrl = imgUrl
  else if (imgUrl.startsWith('//')) fullUrl = `https:${imgUrl}`
  else if (imgUrl.startsWith('/')) fullUrl = `${baseUrl.origin}${imgUrl}`
  else fullUrl = new URL(imgUrl, baseUrl.origin).href
  
  const isFromImageCDN = /(static|cdn|media|img|galleryimage|assets)\./i.test(fullUrl)
  const hasProductKeywords = /(product|gallery|mug|gift|item)/i.test(fullUrl)
  const isImageFile = fullUrl.match(/\.(jpg|jpeg|png|webp|gif)(\?|$)/i)
  
  if ((isFromImageCDN && (hasProductKeywords || isImageFile)) || (hasProductKeywords && isImageFile)) {
    if (!imagesArray.includes(fullUrl)) imagesArray.push(fullUrl)
  }
}

/**
 * Find product URLs from shop homepage or category pages
 */
async function findProductUrls(shopDomain: string, limit: number = 10): Promise<string[]> {
  const baseUrl = `https://${shopDomain}`
  const html = await fetchWebsite(baseUrl)
  
  const productUrls: string[] = []
  const urlPatterns = [
    /<a[^>]*href="([^"]*\/product[^"]*)"[^>]*>/gi,
    /<a[^>]*href="([^"]*\/p\/[^"]*)"[^>]*>/gi,
    /<a[^>]*href="([^"]*\/item[^"]*)"[^>]*>/gi,
  ]
  
  for (const pattern of urlPatterns) {
    const matches = html.matchAll(pattern)
    for (const match of matches) {
      let productUrl = match[1]
      if (productUrl && !productUrl.startsWith('http')) {
        productUrl = new URL(productUrl, baseUrl).href
      }
      if (productUrl && !productUrls.includes(productUrl) && productUrls.length < limit) {
        productUrls.push(productUrl)
      }
    }
  }
  
  return productUrls.slice(0, limit)
}

/**
 * Read available filters from filters.md
 */
function readAvailableFilters(): string[] {
  try {
    const filePath = join(process.cwd(), 'agents/data/filters.md')
    const content = readFileSync(filePath, 'utf-8')
    const filterMatches = content.matchAll(/- \*\*([^\*]+)\*\*/g)
    const filters: string[] = []
    
    for (const match of filterMatches) {
      filters.push(match[1].trim())
    }
    
    return filters
  } catch (error) {
    console.warn('Could not read filters.md:', error)
    return []
  }
}

/**
 * Get all categories from Supabase
 */
async function getAllCategories(supabase: ReturnType<typeof createAdminClient>) {
  const { data, error } = await supabase
    .from('categories')
    .select('id, title, slug, parent_id')
  
  if (error) {
    throw new Error(`Failed to fetch categories: ${error.message}`)
  }
  
  return data || []
}

/**
 * Match product to categories
 */
function matchCategories(
  productInfo: ExtractedProductInfo,
  allCategories: Array<{ id: string; title: string; slug: string }>
): string[] {
  const matchedCategoryIds: string[] = []
  const searchText = `${productInfo.title} ${productInfo.textContent || ''}`.toLowerCase()
  
  for (const category of allCategories) {
    const categoryTitle = category.title.toLowerCase()
    if (searchText.includes(categoryTitle) || categoryTitle.includes(searchText.substring(0, 20))) {
      if (!matchedCategoryIds.includes(category.id)) {
        matchedCategoryIds.push(category.id)
      }
    }
  }
  
  return [...new Set(matchedCategoryIds)]
}


/**
 * Determine age filters based on product info
 */
function determineAgeFilters(
  productInfo: ExtractedProductInfo,
  availableFilters: string[]
): string[] {
  const ageFilters: string[] = []
  const searchText = `${productInfo.title} ${productInfo.textContent || ''}`.toLowerCase()
  
  if (searchText.includes('baby') || searchText.includes('newborn') || searchText.includes('0-12')) {
    ageFilters.push('0 to 12 months')
  }
  if (searchText.includes('toddler') || searchText.includes('1-3') || searchText.includes('1 to 3')) {
    ageFilters.push('1 - 3 years')
  }
  if (searchText.includes('preschool') || searchText.includes('3-5') || searchText.includes('3 to 5')) {
    ageFilters.push('3 - 5 years')
  }
  if (searchText.includes('child') || searchText.includes('kid') || searchText.includes('5-7')) {
    ageFilters.push('5 - 7 years')
  }
  if (searchText.includes('teen') || searchText.includes('13-17')) {
    ageFilters.push('13 - 17 years')
  }
  if (searchText.includes('adult') || searchText.includes('18+')) {
    ageFilters.push('Adults')
  }
  
  return ageFilters.filter(f => availableFilters.includes(f))
}

/**
 * Run a script and wait for it to complete
 */
async function runScript(
  script: string,
  args: string[],
  env: Record<string, string> = {}
): Promise<{ success: boolean; output: string; error?: string }> {
  return new Promise((resolve) => {
    const child = spawn('tsx', [script, ...args], {
      env: { ...process.env, ...env },
      stdio: ['inherit', 'pipe', 'pipe'],
    })

    let stdout = ''
    let stderr = ''

    child.stdout?.on('data', (data: Buffer) => {
      stdout += data.toString()
    })

    child.stderr?.on('data', (data: Buffer) => {
      stderr += data.toString()
    })

    child.on('close', (code: number | null) => {
      resolve({
        success: code === 0,
        output: stdout,
        error: stderr || undefined,
      })
    })

    child.on('error', (error: Error) => {
      resolve({
        success: false,
        output: stdout,
        error: error.message || String(error),
      })
    })
  })
}

/**
 * Main function
 */
async function main() {
  const args = process.argv.slice(2)
  
  if (args.length === 0) {
    console.error('Usage: tsx scripts/new-products.ts <shop-identifier> [product-url-1] [product-url-2] ...')
    console.error('   or: tsx scripts/new-products.ts <shop-identifier> --limit <number>')
    process.exit(1)
  }
  
  const shopIdentifier = args[0]
  let productUrls: string[] = []
  let limit = 10
  let fromJsonFile: string | null = null
  const apiMode = args.includes('--api-mode')
  
    if (args.includes('--from-json')) {
      const jsonIndex = args.indexOf('--from-json')
      fromJsonFile = args[jsonIndex + 1]
      // If path doesn't start with tmp/, add it
      if (fromJsonFile && !fromJsonFile.startsWith('tmp/') && !fromJsonFile.startsWith('/')) {
        fromJsonFile = `tmp/${fromJsonFile}`
      }
    } else if (args.includes('--limit')) {
    const limitIndex = args.indexOf('--limit')
    limit = parseInt(args[limitIndex + 1]) || 10
    productUrls = []
  } else {
    if (args.length > 1) {
      if (args[1].endsWith('.json')) {
        fromJsonFile = args[1]
      } else if (args[1].startsWith('http')) {
        productUrls = args.slice(1).filter(arg => arg.startsWith('http') && !arg.startsWith('--'))
      }
    }
  }

  if (apiMode && !fromJsonFile) {
    console.warn('‚ö†Ô∏è  --api-mode requires --from-json flag')
  }
  
  console.log('Starting product processing...')
  console.log(`Shop identifier: ${shopIdentifier}`)
  
  try {
    const supabase = createAdminClient()
    
    console.log('\nüîç Looking up shop...')
    
    let { data: shop, error: shopError } = await supabase
      .from('shops')
      .select('id, domain, title')
      .eq('domain', shopIdentifier)
      .eq('active', true)
      .maybeSingle()
    
    if (!shop && shopIdentifier.match(/^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i)) {
      const { data: shopById } = await supabase
        .from('shops')
        .select('id, domain, title')
        .eq('id', shopIdentifier)
        .eq('active', true)
        .maybeSingle()
      shop = shopById
    }
    
    if (!shop) {
      const { data: shopByTitle } = await supabase
        .from('shops')
        .select('id, domain, title')
        .ilike('title', `%${shopIdentifier}%`)
        .eq('active', true)
        .limit(1)
        .maybeSingle()
      shop = shopByTitle
    }
    
    if (!shop) {
      throw new Error(`Shop not found: ${shopIdentifier}. Please check the domain, ID, or title.`)
    }
    
    console.log(`‚úì Found shop: ${shop.title} (${shop.domain})`)
    
    let products: Array<ProductData & { extractedInfo: ExtractedProductInfo }> = []
    
    if (fromJsonFile) {
      console.log(`\nüìÇ Loading products from JSON file: ${fromJsonFile}`)
      try {
        const jsonContent = readFileSync(join(process.cwd(), fromJsonFile), 'utf-8')
        const jsonProducts = JSON.parse(jsonContent)
        
        products = jsonProducts.map((p: any) => {
          const uniqueCategories = p.categories ? [...new Set(p.categories)] : []
          
          if (p.categories && uniqueCategories.length !== p.categories.length) {
            console.log(`   ‚ö†Ô∏è  Product "${p.title}": Removed ${p.categories.length - uniqueCategories.length} duplicate categories from JSON`)
          }
          
          return {
            shop_id: shop.id,
            title: p.title,
            slug: p.slug || generateSlug(p.title),
            url: p.url,
            price: p.price !== undefined ? (typeof p.price === 'number' ? p.price : parseFloat(p.price)) : null,
            price_discount: p.price_discount !== undefined ? (typeof p.price_discount === 'number' ? p.price_discount : parseFloat(p.price_discount)) : null,
            description: p.description || '',
            specifications: p.specifications || {},
            images: p.images || [],
            filters: p.filters || {},
            categories: uniqueCategories,
            extractedInfo: {
              title: p.title,
              url: p.url,
              price: p.price !== undefined ? (typeof p.price === 'number' ? p.price : parseFloat(p.price)) : null,
              price_discount: p.price_discount !== undefined ? (typeof p.price_discount === 'number' ? p.price_discount : parseFloat(p.price_discount)) : null,
              images: p.images || [],
              textContent: p.textContent || ''
            }
          }
        })
        
        console.log(`‚úì Loaded ${products.length} products from JSON`)
      } catch (error) {
        throw new Error(`Failed to load JSON file: ${error}`)
      }
    }
    
    if (products.length === 0 && !apiMode) {
      if (productUrls.length === 0) {
        console.log(`\nüîç Finding products (limit: ${limit})...`)
        productUrls = await findProductUrls(shop.domain, limit)
        console.log(`‚úì Found ${productUrls.length} product URLs`)
      } else {
        console.log(`\nüìã Using provided product URLs: ${productUrls.length}`)
      }
      
      if (productUrls.length === 0) {
        console.warn('‚ö†Ô∏è  No products found. Please provide product URLs manually.')
        process.exit(0)
      }
    }
    
    let allCategories: any[] = []
    let availableFilters: string[] = []
    
    if (!apiMode) {
      allCategories = await getAllCategories(supabase)
      availableFilters = readAvailableFilters()
    }
    
    if (!apiMode && productUrls.length > 0) {
      console.log(`\nüì¶ Processing ${productUrls.length} products...\n`)
    }
    
    if (products.length === 0 && !apiMode) {
      for (let i = 0; i < productUrls.length; i++) {
        const productUrl = productUrls[i]
        console.log(`\n[${i + 1}/${productUrls.length}] Processing: ${productUrl}`)
        
        try {
          const html = await fetchWebsite(productUrl)
          
          // Debug: Check if HTML contains product page elements for Amazon links
          if (productUrl.includes('amzn.to') || productUrl.includes('amazon.com')) {
            const hasProductContent = html.includes('productTitle') || 
                                    html.includes('landingImage') || 
                                    html.includes('id="title"') ||
                                    html.includes('data-asin')
            if (!hasProductContent && html.length < 10000) {
              console.warn(`   ‚ö†Ô∏è  HTML does not appear to contain product page content`)
              console.warn(`   ‚ÑπÔ∏è  HTML length: ${html.length} characters`)
            }
          }
          
          const extractedInfo = extractProductInfo(html, productUrl)
          
          if (!extractedInfo.title) {
            console.warn('‚ö†Ô∏è  Could not extract title, skipping...')
            continue
          }
          
          // Debug: Log extracted images count
          if (extractedInfo.images && extractedInfo.images.length > 0) {
            console.log(`   üì∏ Extracted ${extractedInfo.images.length} image(s) from product page`)
            if (extractedInfo.images[0]) {
              console.log(`   üì∏ First image: ${extractedInfo.images[0].substring(0, 60)}...`)
            }
          } else {
            console.warn(`   ‚ö†Ô∏è  No images extracted from product page`)
          }
          
          const matchedCategoryIds = matchCategories(extractedInfo, allCategories)
          const ageFilters = determineAgeFilters(extractedInfo, availableFilters)
          
          const product: ProductData & { extractedInfo: ExtractedProductInfo } = {
            shop_id: shop.id,
            title: extractedInfo.title,
            slug: generateSlug(extractedInfo.title),
            url: productUrl,
            price: extractedInfo.price ?? null,
            price_discount: extractedInfo.price_discount ?? null,
            description: '',
            specifications: extractedInfo.specifications || {},
            images: extractedInfo.images || [],
            filters: ageFilters.length > 0 ? { age: ageFilters } : {},
            categories: matchedCategoryIds,
            extractedInfo
          }
          
          products.push(product)
          
          console.log(`‚úì Extracted: ${product.title}`)
          console.log(`  Price: ${product.price !== null ? `‚Ç¨${product.price.toFixed(2)}` : 'not found'}`)
          if (product.price_discount) {
            console.log(`  Discount Price: ‚Ç¨${product.price_discount.toFixed(2)}`)
          }
          console.log(`  Images: ${product.images.length}`)
          console.log(`  Categories: ${matchedCategoryIds.length}`)
          console.log(`  Age filters: ${ageFilters.length > 0 ? ageFilters.join(', ') : 'none'}`)
          
        } catch (error) {
          console.error(`‚ùå Error processing product: ${error}`)
          continue
        }
      }
    }
    
    // Always insert products into database (don't save to JSON)
    // Automatically generate descriptions from extracted information
    console.log('\n\nüíæ Inserting products into Supabase...')
    
    for (const product of products) {
        const minDescriptionLength = apiMode ? 10 : 100
        
        // Automatically generate description from extracted information if missing
        if (!product.description || product.description.trim().length < minDescriptionLength) {
          // Try to extract description from textContent first
          if (product.extractedInfo?.textContent && product.extractedInfo.textContent.trim().length > minDescriptionLength) {
            // Use first part of textContent as description
            const textContent = product.extractedInfo.textContent
              .replace(/<[^>]*>/g, '') // Remove HTML tags
              .replace(/\s+/g, ' ') // Normalize whitespace
              .trim()
            
            // Take first meaningful sentences (up to 500 chars)
            const sentences = textContent.match(/[^.!?]+[.!?]+/g) || []
            let description = ''
            for (const sentence of sentences) {
              if ((description + sentence).length <= 500) {
                description += sentence
              } else {
                break
              }
            }
            
            if (description.trim().length >= minDescriptionLength) {
              product.description = description.trim()
              console.log(`   ‚ÑπÔ∏è  Generated description from product content (${product.description.length} characters)`)
            }
          }
          
          // If still no description, generate from available information
          if (!product.description || product.description.trim().length < minDescriptionLength) {
            if (apiMode && product.specifications) {
              const specs = product.specifications as any
              product.description = `Product: ${product.title}. ${specs.manufacturer ? `Manufactured by ${specs.manufacturer}. ` : ''}${specs.category ? `Category: ${specs.category}. ` : ''}${specs.instock !== undefined ? `Stock status: ${specs.instock ? 'In stock' : 'Out of stock'}.` : ''}`
            } else {
              // Generate a minimal description from available information
              const specs = product.specifications as any
              let minimalDescription = `${product.title}.`
              
              // Add textContent preview if available
              if (product.extractedInfo?.textContent) {
                const preview = product.extractedInfo.textContent
                  .replace(/<[^>]*>/g, '')
                  .replace(/\s+/g, ' ')
                  .trim()
                  .substring(0, 200)
                if (preview) {
                  minimalDescription += ` ${preview}...`
                }
              }
              
              if (specs) {
                if (specs.manufacturer) minimalDescription += ` Manufactured by ${specs.manufacturer}.`
                if (specs.category) minimalDescription += ` Category: ${specs.category}.`
                if (specs.dimensions) minimalDescription += ` Dimensions: ${JSON.stringify(specs.dimensions)}.`
                if (specs.materials) minimalDescription += ` Materials: ${Array.isArray(specs.materials) ? specs.materials.join(', ') : specs.materials}.`
              }
              if (product.filters && typeof product.filters === 'object' && 'age' in product.filters) {
                const ages = (product.filters as any).age
                if (Array.isArray(ages) && ages.length > 0) {
                  minimalDescription += ` Suitable for ages: ${ages.join(', ')}.`
                }
              }
              // Add generic product description
              minimalDescription += ` This product is available for purchase.`
              
              if (minimalDescription.length >= minDescriptionLength) {
                product.description = minimalDescription
                console.log(`   ‚ÑπÔ∏è  Generated description for product (${minimalDescription.length} characters)`)
              } else {
                // If still too short, pad it
                const padding = ' '.repeat(minDescriptionLength - minimalDescription.length + 10)
                product.description = minimalDescription + padding
                console.log(`   ‚ÑπÔ∏è  Generated description with padding for product`)
              }
            }
          }
        }
        
        try {
          // CRITICAL: Verify images are extracted from the correct product page
          // If images array is empty or seems wrong, re-extract from the product URL
          if (!product.images || product.images.length === 0) {
            console.warn(`‚ö†Ô∏è  No images found in product data. Re-extracting from product URL...`)
            try {
              const html = await fetchWebsite(product.url)
              const reExtractedInfo = extractProductInfo(html, product.url)
              if (reExtractedInfo.images && reExtractedInfo.images.length > 0) {
                product.images = reExtractedInfo.images
                console.log(`   ‚úì Re-extracted ${product.images.length} image(s) from product page`)
              } else {
                console.error(`   ‚ùå Still no images found after re-extraction. Skipping product.`)
                continue
              }
            } catch (error) {
              console.error(`   ‚ùå Error re-extracting images: ${error}`)
              continue
            }
          }
          
          // Validate product images before insertion
          const imageValidation = validateProductImages(product.images || [], product.url, product.title)
          if (!imageValidation.valid) {
            console.error(`\n‚ùå IMAGE VALIDATION FAILED for product: ${product.title}`)
            imageValidation.warnings.forEach(warning => console.error(`   ${warning}`))
            console.error(`   URL: ${product.url}`)
            console.error(`   Please fix the images before inserting the product.`)
            console.error(`   Skipping product insertion...\n`)
            continue
          } else if (imageValidation.warnings.length > 0) {
            console.log(`\n‚ÑπÔ∏è  Image validation warnings (before insertion):`)
            imageValidation.warnings.forEach(warning => console.log(`   ${warning}`))
          }
          
          // Check if product already exists by URL (most reliable check)
          console.log(`   üîç Checking if product already exists...`)
          const { data: existingProduct, error: checkError } = await supabase
            .from('products')
            .select('id, title, slug, url')
            .eq('url', product.url)
            .maybeSingle()
          
          if (checkError && checkError.code !== 'PGRST116') { // PGRST116 = no rows returned
            console.warn(`   ‚ö†Ô∏è  Error checking for existing product: ${checkError.message}`)
          }
          
          if (existingProduct) {
            console.warn(`   ‚ö†Ô∏è  Product already exists! Skipping...`)
            console.warn(`      Existing product ID: ${existingProduct.id}`)
            console.warn(`      Title: ${existingProduct.title}`)
            console.warn(`      URL: ${existingProduct.url}`)
            continue
          }
          
          // Also check by slug for the same shop (in case URL changed but slug is same)
          const { data: existingBySlug } = await supabase
            .from('products')
            .select('id, title, slug, url')
            .eq('shop_id', product.shop_id)
            .eq('slug', product.slug)
            .maybeSingle()
          
          if (existingBySlug) {
            console.warn(`   ‚ö†Ô∏è  Product with same slug already exists for this shop! Skipping...`)
            console.warn(`      Existing product ID: ${existingBySlug.id}`)
            console.warn(`      Title: ${existingBySlug.title}`)
            console.warn(`      Slug: ${existingBySlug.slug}`)
            // Add to checklist even if product already exists (to prevent re-processing)
            const ageFilters = product.filters && typeof product.filters === 'object' && 'age' in product.filters
              ? (product.filters as any).age
              : []
            addToChecklist(
              product.url,
              product.title,
              existingBySlug.id,
              Array.isArray(ageFilters) ? ageFilters : [],
              ''
            )
            continue
          }
          
          const { data: insertedProduct, error: productError } = await supabase
            .from('products')
            .insert({
              shop_id: product.shop_id,
              title: product.title,
              slug: product.slug,
              url: product.url,
              price: product.price,
              price_discount: product.price_discount,
              description: product.description,
              specifications: product.specifications,
              images: product.images,
              filters: product.filters
            })
            .select()
            .single()
          
          if (productError) {
            if (productError.code === '23505') {
              console.warn(`‚ö†Ô∏è  Product "${product.title}" already exists (unique constraint violation)`)
            } else {
              throw productError
            }
            continue
          }
          
          console.log(`‚úÖ Created product: ${product.title} (ID: ${insertedProduct.id})`)
          
          // Validate product images after insertion (double-check)
          const postInsertValidation = validateProductImages(product.images || [], product.url, product.title)
          if (!postInsertValidation.valid) {
            console.warn(`\n‚ö†Ô∏è  IMAGE VALIDATION FAILED for product: ${product.title}`)
            postInsertValidation.warnings.forEach(warning => console.warn(`   ${warning}`))
            console.warn(`   Product ID: ${insertedProduct.id}`)
            console.warn(`   URL: ${product.url}`)
            console.warn(`   Please check and fix the images manually using:`)
            console.warn(`   npx tsx scripts/fix-product-images.ts ${insertedProduct.id} <image-url-1> [image-url-2] ...`)
          } else if (postInsertValidation.warnings.length > 0) {
            console.log(`\n‚ÑπÔ∏è  Image validation warnings:`)
            postInsertValidation.warnings.forEach(warning => console.log(`   ${warning}`))
          } else {
            console.log(`   ‚úì Images validated: ${product.images?.length || 0} image(s)`)
          }
          
          if (apiMode) {
            console.log(`   Product ID for threads: ${insertedProduct.id}`)
          }
          
          let categoryTitle = ''
          if (product.categories && product.categories.length > 0) {
            const uniqueCategoryIds = [...new Set(product.categories)]
            
            if (uniqueCategoryIds.length !== product.categories.length) {
              console.log(`   ‚ö†Ô∏è  Removed ${product.categories.length - uniqueCategoryIds.length} duplicate category associations`)
            }
            
            const categoryInserts = uniqueCategoryIds.map(categoryId => ({
              product_id: insertedProduct.id,
              category_id: categoryId
            }))
            
            const { error: categoryError } = await supabase
              .from('product_categories')
              .upsert(categoryInserts, { onConflict: 'product_id,category_id' })
            
            if (categoryError) {
              console.warn(`‚ö†Ô∏è  Error linking categories: ${categoryError.message}`)
            } else {
              console.log(`   Linked to ${uniqueCategoryIds.length} categories`)
              
              // Get category title for checklist
              if (uniqueCategoryIds.length > 0) {
                const { data: categoryData } = await supabase
                  .from('categories')
                  .select('title')
                  .eq('id', uniqueCategoryIds[0])
                  .maybeSingle()
                if (categoryData) {
                  categoryTitle = categoryData.title
                }
              }
            }
          }
          
          // Add to checklist if product is from Amazon (even if product already existed)
          const ageFilters = product.filters && typeof product.filters === 'object' && 'age' in product.filters
            ? (product.filters as any).age
            : []
          addToChecklist(
            product.url,
            product.title,
            insertedProduct.id,
            Array.isArray(ageFilters) ? ageFilters : [],
            categoryTitle
          )
          
          // Automatically insert thread for the product if thread text and keywords are provided
          // According to agents/new-products.md, thread text should be generated by AI assistant
          // and passed to this script as part of product data
          if (!apiMode && product.thread_text && product.thread_keywords) {
            console.log(`\nüìù Inserting thread for: ${product.title}`)
            console.log(`   Product ID: ${insertedProduct.id}`)
            console.log(`   Thread text length: ${product.thread_text.length} characters`)
            console.log(`   Keywords: ${product.thread_keywords}`)
            
            try {
              // Call new-product-threads.ts with thread text and keywords directly
              // Escape quotes in thread text and keywords for command line
              const escapedText = product.thread_text.replace(/"/g, '\\"')
              const escapedKeywords = product.thread_keywords.replace(/"/g, '\\"')
              
              const result = await runScript(
                'scripts/new-product-threads.ts',
                [
                  insertedProduct.id,
                  '--text',
                  escapedText,
                  '--keywords',
                  escapedKeywords
                ]
              )
              
              if (result.success) {
                console.log(`   ‚úÖ Thread inserted successfully`)
              } else {
                console.error(`   ‚ö†Ô∏è  Error inserting thread: ${result.error}`)
                console.error(`   ‚ö†Ô∏è  Thread text: ${product.thread_text.substring(0, 100)}...`)
              }
            } catch (threadError) {
              console.error(`   ‚ö†Ô∏è  Error inserting thread: ${threadError}`)
              console.error(`   ‚ö†Ô∏è  Thread generation failed, but product was inserted successfully.`)
              console.error(`   ‚ö†Ô∏è  You can manually insert thread using:`)
              console.error(`      npm run new-product-threads ${insertedProduct.id} --text "${product.thread_text}" --keywords "${product.thread_keywords}"`)
            }
          } else if (!apiMode) {
            console.log(`\n‚ö†Ô∏è  Thread text and keywords not provided for: ${product.title}`)
            console.log(`   ‚ÑπÔ∏è  According to agents/new-products.md, AI assistant should generate thread text and keywords`)
            console.log(`   ‚ÑπÔ∏è  Thread text must be max 460 characters (without affiliate link)`)
            console.log(`   ‚ÑπÔ∏è  You can manually insert thread using:`)
            console.log(`      npm run new-product-threads ${insertedProduct.id} --text "<thread text>" --keywords "<keywords>"`)
          } else {
            console.log(`   ‚ÑπÔ∏è  API mode: Thread generation skipped (will be done separately)`)
          }
          
        } catch (error) {
          console.error(`‚ùå Error inserting product "${product.title}": ${error}`)
          continue
        }
      }
      
      console.log('\n‚úÖ Product processing complete!')
    
  } catch (error) {
    console.error('\n‚ùå Error:', error)
    process.exit(1)
  }
}

main()
